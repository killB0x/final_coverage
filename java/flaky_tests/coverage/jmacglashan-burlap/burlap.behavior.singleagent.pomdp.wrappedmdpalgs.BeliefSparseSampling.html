<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
           "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<title>Coverage Report</title>
<link title="Style" type="text/css" rel="stylesheet" href="css/main.css"/>
<script type="text/javascript" src="js/popup.js"></script>
</head>
<body>
<h5>Coverage Report - burlap.behavior.singleagent.pomdp.wrappedmdpalgs.BeliefSparseSampling</h5>
<div class="separator">&nbsp;</div>
<table class="report">
<thead><tr>  <td class="heading">Classes in this File</td>  <td class="heading"><a class="dfn" href="help.html" onclick="popupwindow('help.html'); return false;">Line Coverage</a></td>  <td class="heading"><a class="dfn" href="help.html" onclick="popupwindow('help.html'); return false;">Branch Coverage</a></td>  <td class="heading"><a class="dfn" href="help.html" onclick="popupwindow('help.html'); return false;">Complexity</a></td></tr></thead>
  <tr><td><a href="burlap.behavior.singleagent.pomdp.wrappedmdpalgs.BeliefSparseSampling.html">BeliefSparseSampling</a></td><td><table cellpadding="0px" cellspacing="0px" class="percentgraph"><tr class="percentgraph"><td align="right" class="percentgraph" width="40">0%</td><td class="percentgraph"><div class="percentgraph"><div class="greenbar" style="width:0px"><span class="text">0/31</span></div></div></td></tr></table></td><td><table cellpadding="0px" cellspacing="0px" class="percentgraph"><tr class="percentgraph"><td align="right" class="percentgraph" width="40">0%</td><td class="percentgraph"><div class="percentgraph"><div class="greenbar" style="width:0px"><span class="text">0/4</span></div></div></td></tr></table></td><td class="value"><span class="hidden">1.2222222222222223;</span>1.222</td></tr>

</table>
<div class="separator">&nbsp;</div>
<table cellspacing="0" cellpadding="0" class="src">
<tr>  <td class="numLine">&nbsp;1</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">package</span> burlap.behavior.singleagent.pomdp.wrappedmdpalgs;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;2</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;3</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.policy.GreedyQPolicy;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;4</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.policy.Policy;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;5</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.singleagent.Episode;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;6</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.singleagent.MDPSolver;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;7</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.singleagent.planning.Planner;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;8</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;9</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.singleagent.pomdp.BeliefPolicyAgent;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;10</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.valuefunction.QProvider;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;11</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.behavior.valuefunction.QValue;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;12</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.domain.singleagent.pomdp.tiger.TigerDomain;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;13</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.domain.singleagent.pomdp.tiger.TigerState;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;14</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.mdp.core.action.Action;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;15</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.mdp.core.state.State;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;16</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.mdp.singleagent.SADomain;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;17</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.mdp.singleagent.pomdp.BeliefMDPGenerator;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;18</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.mdp.singleagent.pomdp.PODomain;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;19</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.mdp.singleagent.pomdp.SimulatedPOEnvironment;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;20</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.mdp.singleagent.pomdp.beliefstate.BeliefState;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;21</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.statehashing.HashableStateFactory;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;22</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> burlap.statehashing.ReflectiveHashableStateFactory;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;23</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;24</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">import</span> java.util.List;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;25</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;26</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;27</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">/**</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;28</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment"> * A POMDP planning algorithm that converts a POMDP into a Belief MDP and then uses {@link burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling}</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;29</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment"> * to solve it. If the full transition dynamics are used (set c in the constructor to -1), then it provides and optimal finite horizon POMDP policy.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;30</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment"> */</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;31</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="keyword">public</span> <span class="keyword">class</span> BeliefSparseSampling <span class="keyword">extends</span> MDPSolver <span class="keyword">implements</span> Planner, QProvider {</pre></td></tr>
<tr>  <td class="numLine">&nbsp;32</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;33</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="comment">/**</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;34</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * The belief MDP domain to solve.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;35</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         */</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;36</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">protected</span> SADomain                                                        beliefMDP;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;37</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;38</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;39</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="comment">/**</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;40</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * The {@link burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling} planning instance to solve the problem.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;41</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         */</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;42</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">protected</span> SparseSampling                                        mdpPlanner;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;43</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;44</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;45</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="comment">/**</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;46</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * Initializes the planner.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;47</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * @param domain the POMDP domain</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;48</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * @param discount the discount factor</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;49</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * @param hashingFactory the Belief MDP {@link burlap.statehashing.HashableStateFactory} that {@link burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling} will use.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;50</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * @param h the height of the {@link burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling} tree.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;51</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * @param c the number of samples {@link burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling} will use. Set to -1 to use the full BeliefMDP transition dynamics.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;52</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         */</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;53</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;        <span class="keyword">public</span> BeliefSparseSampling(PODomain domain, <span class="keyword">double</span> discount, HashableStateFactory hashingFactory, <span class="keyword">int</span> h, <span class="keyword">int</span> c){</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;54</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        </pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;55</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">this</span>.solverInit(domain, discount, hashingFactory);</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;56</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                BeliefMDPGenerator bdgen = <span class="keyword">new</span> BeliefMDPGenerator(domain);</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;57</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">this</span>.beliefMDP = (SADomain)bdgen.generateDomain();</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;58</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                </pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;59</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">this</span>.mdpPlanner = <span class="keyword">new</span> SparseSampling(<span class="keyword">this</span>.beliefMDP, discount, hashingFactory, h, Math.max(1, c));</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;60</td>  <td class="nbHitsUncovered"><a title="Line 60: Conditional coverage 0% (0/2).">&nbsp;0</a></td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;<a title="Line 60: Conditional coverage 0% (0/2).">                <span class="keyword">if</span>(c &lt; 1){</a></span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;61</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                        <span class="keyword">this</span>.mdpPlanner.setComputeExactValueFunction(<span class="keyword">true</span>);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;62</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;63</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                </pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;64</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;        }</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;65</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;66</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;67</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="comment">/**</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;68</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * Returns the generated Belief MDP that will be solved.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;69</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * @return the generated Belief MDP that will be solved.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;70</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         */</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;71</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> SADomain getBeliefMDP(){</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;72</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">return</span> <span class="keyword">this</span>.beliefMDP;</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;73</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;74</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;75</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="comment">/**</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;76</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * Returns the {@link burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling} planning used to solve the Belief MDP.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;77</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         * @return the {@link burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling} planning used to solve the Belief MDP.</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;78</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">         */</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;79</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> SparseSampling getSparseSamplingPlanner(){</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;80</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">return</span> <span class="keyword">this</span>.mdpPlanner;</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;81</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;82</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;83</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        @Override</pre></td></tr>
<tr>  <td class="numLine">&nbsp;84</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> List&lt;QValue&gt; qValues(State s) {</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;85</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">return</span> <span class="keyword">this</span>.mdpPlanner.qValues(s);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;86</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;87</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;88</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        @Override</pre></td></tr>
<tr>  <td class="numLine">&nbsp;89</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> <span class="keyword">double</span> qValue(State s, Action a) {</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;90</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">return</span> <span class="keyword">this</span>.mdpPlanner.qValue(s, a);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;91</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;92</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        </pre></td></tr>
<tr>  <td class="numLine">&nbsp;93</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        @Override</pre></td></tr>
<tr>  <td class="numLine">&nbsp;94</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> Policy planFromState(State initialState){</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;95</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">this</span>.mdpPlanner.planFromState(initialState);</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;96</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">return</span> <span class="keyword">new</span> GreedyQPolicy(<span class="keyword">this</span>);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;97</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;98</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;99</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        @Override</pre></td></tr>
<tr>  <td class="numLine">&nbsp;100</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> <span class="keyword">void</span> resetSolver() {</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;101</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">this</span>.mdpPlanner.resetSolver();</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;102</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;        }</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;103</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;104</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        @Override</pre></td></tr>
<tr>  <td class="numLine">&nbsp;105</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> <span class="keyword">double</span> value(State s) {</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;106</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                <span class="keyword">return</span> Helper.maxQ(<span class="keyword">this</span>, s);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;107</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;108</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;109</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;110</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        </pre></td></tr>
<tr>  <td class="numLine">&nbsp;111</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        </pre></td></tr>
<tr>  <td class="numLine">&nbsp;112</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(String [] args){</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;113</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                TigerDomain tiger = <span class="keyword">new</span> TigerDomain(<span class="keyword">true</span>);</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;114</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                PODomain domain = (PODomain)tiger.generateDomain();</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;115</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                BeliefState initialBelief = TigerDomain.getInitialBeliefState(domain);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;116</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;117</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                BeliefSparseSampling bss = <span class="keyword">new</span> BeliefSparseSampling(domain, 0.99, <span class="keyword">new</span> ReflectiveHashableStateFactory(), 10, -1);</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;118</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                Policy p = <span class="keyword">new</span> GreedyQPolicy(bss);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;119</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;120</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                SimulatedPOEnvironment env = <span class="keyword">new</span> SimulatedPOEnvironment(domain);</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;121</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                env.setCurStateTo(<span class="keyword">new</span> TigerState(TigerDomain.VAL_LEFT));</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;122</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;123</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                BeliefPolicyAgent agent = <span class="keyword">new</span> BeliefPolicyAgent(domain, env, p);</span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;124</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                agent.setBeliefState(initialBelief);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;125</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;126</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLine">&nbsp;127</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;128</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                agent.setEnvironment(env);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;129</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                </pre></td></tr>
<tr>  <td class="numLine">&nbsp;130</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                <span class="comment">/*</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;131</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">                State initialBeliefStateOb = BeliefMDPGenerator.getBeliefMDPState(bss.getBeliefMDP(), initialBelief);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;132</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">                List&lt;QValue&gt; qs = bss.getQs(initialBeliefStateOb);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;133</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">                for(QValue q : qs){</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;134</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">                        System.out.println(q.a.toString() + ": " + q.q);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;135</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">                }</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;136</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;<span class="comment">                */</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;137</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;138</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                Episode ea = agent.actUntilTerminalOrMaxSteps(30);</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;139</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;</pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;140</td>  <td class="nbHitsUncovered"><a title="Line 140: Conditional coverage 0% (0/2).">&nbsp;0</a></td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;<a title="Line 140: Conditional coverage 0% (0/2).">                <span class="keyword">for</span>(<span class="keyword">int</span> i = 0; i &lt; ea.numTimeSteps()-1; i++){</a></span></pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;141</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;                        System.out.println(ea.action(i) + <span class="string">" "</span> + ea.reward(i+1));</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;142</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                }</pre></td></tr>
<tr>  <td class="numLine">&nbsp;143</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                </pre></td></tr>
<tr>  <td class="numLine">&nbsp;144</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;                </pre></td></tr>
<tr>  <td class="numLineCover">&nbsp;145</td>  <td class="nbHitsUncovered">&nbsp;0</td>  <td class="src"><pre class="src"><span class="srcUncovered">&nbsp;        }</span></pre></td></tr>
<tr>  <td class="numLine">&nbsp;146</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;        </pre></td></tr>
<tr>  <td class="numLine">&nbsp;147</td>  <td class="nbHits">&nbsp;</td>
  <td class="src"><pre class="src">&nbsp;}</pre></td></tr>
</table>

<div class="footer">Report generated by <a href="http://cobertura.sourceforge.net/" target="_top">Cobertura</a> 2.1.1 on 3/25/25 7:01 PM.</div>
</body>
</html>
