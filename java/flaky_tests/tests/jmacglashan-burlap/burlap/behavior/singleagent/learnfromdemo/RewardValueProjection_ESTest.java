/*
 * This file was automatically generated by EvoSuite
 * Sun Nov 06 01:52:30 GMT 2022
 */

package burlap.behavior.singleagent.learnfromdemo;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.runtime.EvoAssertions.*;
import burlap.behavior.singleagent.learnfromdemo.RewardValueProjection;
import burlap.behavior.singleagent.planning.stochastic.sparsesampling.SparseSampling;
import burlap.behavior.valuefunction.QValue;
import burlap.domain.singleagent.blockdude.state.BlockDudeAgent;
import burlap.domain.singleagent.blockdude.state.BlockDudeCell;
import burlap.domain.singleagent.blockdude.state.BlockDudeState;
import burlap.mdp.auxiliary.common.NullTermination;
import burlap.mdp.auxiliary.common.SinglePFTF;
import burlap.mdp.auxiliary.stateconditiontest.TFGoalCondition;
import burlap.mdp.core.action.Action;
import burlap.mdp.core.action.ActionType;
import burlap.mdp.core.action.SimpleAction;
import burlap.mdp.core.action.UniversalActionType;
import burlap.mdp.core.oo.propositional.PropositionalFunction;
import burlap.mdp.core.oo.state.generic.DeepOOState;
import burlap.mdp.core.state.NullState;
import burlap.mdp.core.state.State;
import burlap.mdp.singleagent.SADomain;
import burlap.mdp.singleagent.common.GoalBasedRF;
import burlap.mdp.singleagent.common.NullRewardFunction;
import burlap.mdp.singleagent.common.SingleGoalPFRF;
import burlap.mdp.singleagent.common.UniformCostRF;
import burlap.mdp.singleagent.environment.EnvironmentOutcome;
import burlap.mdp.singleagent.model.RewardFunction;
import burlap.mdp.singleagent.model.SampleModel;
import burlap.statehashing.ReflectiveHashableStateFactory;
import java.util.List;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true) 
public class RewardValueProjection_ESTest extends RewardValueProjection_ESTest_scaffolding {

  @Test(timeout = 4000)
  public void test00()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      RewardValueProjection.CustomRewardNoTermModel rewardValueProjection_CustomRewardNoTermModel0 = new RewardValueProjection.CustomRewardNoTermModel((SampleModel) null, nullRewardFunction0);
      boolean boolean0 = rewardValueProjection_CustomRewardNoTermModel0.terminal((State) null);
      assertFalse(boolean0);
  }

  @Test(timeout = 4000)
  public void test01()  throws Throwable  {
      NullTermination nullTermination0 = new NullTermination();
      TFGoalCondition tFGoalCondition0 = new TFGoalCondition(nullTermination0);
      GoalBasedRF goalBasedRF0 = new GoalBasedRF(tFGoalCondition0, 0.5, 1.0E-15);
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.STATEACTION;
      SADomain sADomain0 = new SADomain();
      ActionType[] actionTypeArray0 = new ActionType[6];
      SimpleAction simpleAction0 = new SimpleAction("GsrB/h");
      UniversalActionType universalActionType0 = new UniversalActionType(simpleAction0);
      actionTypeArray0[0] = (ActionType) universalActionType0;
      actionTypeArray0[1] = (ActionType) universalActionType0;
      actionTypeArray0[2] = (ActionType) universalActionType0;
      actionTypeArray0[3] = (ActionType) universalActionType0;
      actionTypeArray0[4] = (ActionType) universalActionType0;
      actionTypeArray0[5] = (ActionType) universalActionType0;
      sADomain0.setActionTypes(actionTypeArray0);
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(goalBasedRF0, rewardValueProjection_RewardProjectionType0, sADomain0);
      NullState nullState0 = NullState.instance;
      double double0 = rewardValueProjection0.value(nullState0);
      assertEquals(1.0E-15, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test02()  throws Throwable  {
      UniformCostRF uniformCostRF0 = new UniformCostRF();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.SOURCESTATE;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(uniformCostRF0, rewardValueProjection_RewardProjectionType0);
      BlockDudeCell blockDudeCell0 = new BlockDudeCell();
      SimpleAction simpleAction0 = new SimpleAction();
      double double0 = rewardValueProjection0.qValue(blockDudeCell0, simpleAction0);
      assertEquals((-1.0), double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test03()  throws Throwable  {
      BlockDudeState blockDudeState0 = new BlockDudeState();
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection((RewardFunction) null);
      // Undeclared exception!
      try { 
        rewardValueProjection0.value(blockDudeState0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test04()  throws Throwable  {
      SingleGoalPFRF singleGoalPFRF0 = new SingleGoalPFRF((PropositionalFunction) null, (-2017.405917652488), (-2017.405917652488));
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(singleGoalPFRF0);
      BlockDudeAgent blockDudeAgent0 = new BlockDudeAgent();
      // Undeclared exception!
      try { 
        rewardValueProjection0.value(blockDudeAgent0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // class burlap.domain.singleagent.blockdude.state.BlockDudeAgent cannot be cast to class burlap.mdp.core.oo.state.OOState (burlap.domain.singleagent.blockdude.state.BlockDudeAgent and burlap.mdp.core.oo.state.OOState are in unnamed module of loader org.evosuite.instrumentation.InstrumentingClassLoader @6ba4efde)
         //
         verifyException("burlap.mdp.singleagent.common.SingleGoalPFRF", e);
      }
  }

  @Test(timeout = 4000)
  public void test05()  throws Throwable  {
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection((RewardFunction) null);
      DeepOOState deepOOState0 = new DeepOOState();
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValues(deepOOState0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test06()  throws Throwable  {
      SinglePFTF singlePFTF0 = new SinglePFTF((PropositionalFunction) null);
      TFGoalCondition tFGoalCondition0 = new TFGoalCondition(singlePFTF0);
      GoalBasedRF goalBasedRF0 = new GoalBasedRF(tFGoalCondition0);
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(goalBasedRF0);
      BlockDudeCell blockDudeCell0 = new BlockDudeCell("", "Hb3.q,<&83Dd_xBu");
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValues(blockDudeCell0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // class burlap.domain.singleagent.blockdude.state.BlockDudeCell cannot be cast to class burlap.mdp.core.oo.state.OOState (burlap.domain.singleagent.blockdude.state.BlockDudeCell and burlap.mdp.core.oo.state.OOState are in unnamed module of loader org.evosuite.instrumentation.InstrumentingClassLoader @6ba4efde)
         //
         verifyException("burlap.mdp.auxiliary.common.SinglePFTF", e);
      }
  }

  @Test(timeout = 4000)
  public void test07()  throws Throwable  {
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection((RewardFunction) null);
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.ONESTEP;
      rewardValueProjection0.projectionType = rewardValueProjection_RewardProjectionType0;
      ReflectiveHashableStateFactory reflectiveHashableStateFactory0 = new ReflectiveHashableStateFactory();
      SparseSampling sparseSampling0 = new SparseSampling((SADomain) null, 202.060509697736, reflectiveHashableStateFactory0, 3, 3);
      rewardValueProjection0.oneStepBellmanPlanner = sparseSampling0;
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValue((State) null, (Action) null);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Reflective Hashable State should only be used with State objects that also already implement HashableState.
         //
         verifyException("burlap.statehashing.ReflectiveHashableStateFactory", e);
      }
  }

  @Test(timeout = 4000)
  public void test08()  throws Throwable  {
      SimpleAction simpleAction0 = new SimpleAction();
      SingleGoalPFRF singleGoalPFRF0 = new SingleGoalPFRF((PropositionalFunction) null);
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(singleGoalPFRF0);
      BlockDudeAgent blockDudeAgent0 = new BlockDudeAgent();
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValue(blockDudeAgent0, simpleAction0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // class burlap.domain.singleagent.blockdude.state.BlockDudeAgent cannot be cast to class burlap.mdp.core.oo.state.OOState (burlap.domain.singleagent.blockdude.state.BlockDudeAgent and burlap.mdp.core.oo.state.OOState are in unnamed module of loader org.evosuite.instrumentation.InstrumentingClassLoader @6ba4efde)
         //
         verifyException("burlap.mdp.singleagent.common.SingleGoalPFRF", e);
      }
  }

  @Test(timeout = 4000)
  public void test09()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.ONESTEP;
      RewardValueProjection rewardValueProjection0 = null;
      try {
        rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0, (SADomain) null);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test10()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      SimpleAction simpleAction0 = new SimpleAction();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.ONESTEP;
      SADomain sADomain0 = new SADomain();
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0, sADomain0);
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValue((State) null, simpleAction0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // org/apache/commons/lang3/builder/HashCodeBuilder
         //
         verifyException("burlap.statehashing.simple.IISimpleHashableState", e);
      }
  }

  @Test(timeout = 4000)
  public void test11()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      BlockDudeState blockDudeState0 = new BlockDudeState();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.STATEACTION;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0);
      double double0 = rewardValueProjection0.qValue(blockDudeState0, (Action) null);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test12()  throws Throwable  {
      SimpleAction simpleAction0 = new SimpleAction();
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection((RewardFunction) null);
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValue((State) null, simpleAction0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test13()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.STATEACTION;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0);
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValues((State) null);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // RewardValueProjection cannot generate all state-action Q-values because it was notprovided the Domain to enumerate the actions. Use the RewardValueProjection(RewardFunction, RewardProjectionType, Domain) constructor to specify it.
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test14()  throws Throwable  {
      UniformCostRF uniformCostRF0 = new UniformCostRF();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.SOURCESTATE;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(uniformCostRF0, rewardValueProjection_RewardProjectionType0);
      NullState nullState0 = NullState.instance;
      double double0 = rewardValueProjection0.value(nullState0);
      assertEquals((-1.0), double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test15()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0);
      BlockDudeState blockDudeState0 = new BlockDudeState();
      double double0 = rewardValueProjection0.value(blockDudeState0);
      assertEquals(0.0, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test16()  throws Throwable  {
      NullTermination nullTermination0 = new NullTermination();
      GoalBasedRF goalBasedRF0 = new GoalBasedRF(nullTermination0, 489.7656525, 27.687696);
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.SOURCESTATE;
      BlockDudeCell blockDudeCell0 = BlockDudeCell.exit(130, (-2660));
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(goalBasedRF0, rewardValueProjection_RewardProjectionType0);
      SimpleAction simpleAction0 = new SimpleAction();
      double double0 = rewardValueProjection0.qValue(blockDudeCell0, simpleAction0);
      assertEquals(27.687696, double0, 0.01);
  }

  @Test(timeout = 4000)
  public void test17()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      BlockDudeState blockDudeState0 = new BlockDudeState();
      SADomain sADomain0 = new SADomain();
      SimpleAction simpleAction0 = new SimpleAction();
      UniversalActionType universalActionType0 = new UniversalActionType(simpleAction0);
      SADomain sADomain1 = sADomain0.addActionType(universalActionType0);
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.DESTINATIONSTATE;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0, sADomain1);
      List<QValue> list0 = rewardValueProjection0.qValues(blockDudeState0);
      assertFalse(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void test18()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.SOURCESTATE;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0);
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType1 = RewardValueProjection.RewardProjectionType.ONESTEP;
      rewardValueProjection0.projectionType = rewardValueProjection_RewardProjectionType1;
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValues((State) null);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Unknown RewardProjectionType... this shouldn't happen.
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test19()  throws Throwable  {
      NullTermination nullTermination0 = new NullTermination();
      GoalBasedRF goalBasedRF0 = new GoalBasedRF(nullTermination0, 489.7656525, 27.687696);
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.SOURCESTATE;
      BlockDudeCell blockDudeCell0 = BlockDudeCell.exit(130, (-2660));
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(goalBasedRF0, rewardValueProjection_RewardProjectionType0);
      List<QValue> list0 = rewardValueProjection0.qValues(blockDudeCell0);
      assertEquals(1, list0.size());
  }

  @Test(timeout = 4000)
  public void test20()  throws Throwable  {
      UniformCostRF uniformCostRF0 = new UniformCostRF();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.STATEACTION;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(uniformCostRF0, rewardValueProjection_RewardProjectionType0);
      NullState nullState0 = NullState.instance;
      // Undeclared exception!
      try { 
        rewardValueProjection0.value(nullState0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // RewardValueProjection cannot generate all state-action Q-values because it was notprovided the Domain to enumerate the actions. Use the RewardValueProjection(RewardFunction, RewardProjectionType, Domain) constructor to specify it.
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test21()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      SADomain sADomain0 = new SADomain();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.ONESTEP;
      SimpleAction simpleAction0 = new SimpleAction();
      UniversalActionType universalActionType0 = new UniversalActionType("j:~A!lr_kb3S_,A", simpleAction0);
      SADomain sADomain1 = sADomain0.addActionType(universalActionType0);
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0, sADomain1);
      // Undeclared exception!
      try { 
        rewardValueProjection0.qValues((State) null);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // org/apache/commons/lang3/builder/HashCodeBuilder
         //
         verifyException("burlap.statehashing.simple.IISimpleHashableState", e);
      }
  }

  @Test(timeout = 4000)
  public void test22()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      SADomain sADomain0 = new SADomain();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.ONESTEP;
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0, sADomain0);
      List<QValue> list0 = rewardValueProjection0.qValues((State) null);
      assertTrue(list0.isEmpty());
  }

  @Test(timeout = 4000)
  public void test23()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.ONESTEP;
      RewardValueProjection rewardValueProjection0 = null;
      try {
        rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0);
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // If the reward function depends on a 1 step transition (e.g., from a source state to a target state) then to project the value the Domain is needed evaluate the transition dynamics. Use the RewardValueProjection(RewardFunction, RewardProjectionType, Domain) constructor instead to specify.
         //
         verifyException("burlap.behavior.singleagent.learnfromdemo.RewardValueProjection", e);
      }
  }

  @Test(timeout = 4000)
  public void test24()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      NullState nullState0 = NullState.instance;
      RewardValueProjection.RewardProjectionType rewardValueProjection_RewardProjectionType0 = RewardValueProjection.RewardProjectionType.ONESTEP;
      SADomain sADomain0 = new SADomain();
      RewardValueProjection rewardValueProjection0 = new RewardValueProjection(nullRewardFunction0, rewardValueProjection_RewardProjectionType0, sADomain0);
      // Undeclared exception!
      try { 
        rewardValueProjection0.value(nullState0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // org/apache/commons/lang3/builder/HashCodeBuilder
         //
         verifyException("burlap.statehashing.simple.IISimpleHashableState", e);
      }
  }

  @Test(timeout = 4000)
  public void test25()  throws Throwable  {
      NullRewardFunction nullRewardFunction0 = new NullRewardFunction();
      BlockDudeState blockDudeState0 = new BlockDudeState();
      UniversalActionType universalActionType0 = new UniversalActionType("m9~zc&YFl");
      RewardValueProjection.CustomRewardNoTermModel rewardValueProjection_CustomRewardNoTermModel0 = new RewardValueProjection.CustomRewardNoTermModel((SampleModel) null, nullRewardFunction0);
      EnvironmentOutcome environmentOutcome0 = new EnvironmentOutcome(blockDudeState0, universalActionType0.action, blockDudeState0, (-212.06586), false);
      EnvironmentOutcome environmentOutcome1 = rewardValueProjection_CustomRewardNoTermModel0.modifyOutcome(environmentOutcome0);
      assertFalse(environmentOutcome1.terminated);
  }
}
