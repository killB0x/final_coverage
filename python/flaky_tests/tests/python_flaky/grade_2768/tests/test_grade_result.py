# Automatically generated by Pynguin.
import pytest
import grade.result as module_0
import unittest.loader as module_1
import inspect as module_2

def test_case_0():
    none_type_0 = None
    bool_0 = True
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is True
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    list_0 = result_0.getExceptions(result_0)

@pytest.mark.xfail(strict=True)
def test_case_1():
    none_type_0 = None
    bool_0 = False
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is False
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    result_0.getScore(none_type_0)

@pytest.mark.xfail(strict=True)
def test_case_2():
    none_type_0 = None
    module_0.Result(none_type_0, none_type_0, none_type_0)

@pytest.mark.xfail(strict=True)
def test_case_3():
    none_type_0 = None
    bool_0 = False
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is False
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    result_0.parseExceptions(bool_0)

@pytest.mark.xfail(strict=True)
def test_case_4():
    none_type_0 = None
    bool_0 = False
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is False
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    result_0.addFailure(none_type_0, none_type_0)

@pytest.mark.xfail(strict=True)
def test_case_5():
    none_type_0 = None
    bool_0 = False
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is False
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    result_0.addError(none_type_0, bool_0)

@pytest.mark.xfail(strict=True)
def test_case_6():
    none_type_0 = None
    bool_0 = False
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is False
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    result_0.stopTest(none_type_0)

@pytest.mark.xfail(strict=True)
def test_case_7():
    none_type_0 = None
    bool_0 = True
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is True
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    module_1.findTestCases(result_0, suiteClass=bool_0)

@pytest.mark.xfail(strict=True)
def test_case_8():
    none_type_0 = None
    bool_0 = False
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is False
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    var_0 = module_1.findTestCases(result_0, suiteClass=bool_0)
    assert f'{type(var_0).__module__}.{type(var_0).__qualname__}' == 'unittest.suite.TestSuite'
    result_0.parseExceptions(var_0)

@pytest.mark.xfail(strict=True)
def test_case_9():
    none_type_0 = None
    bool_0 = False
    result_0 = module_0.Result(none_type_0, none_type_0, bool_0)
    assert result_0.failfast is False
    assert result_0.failures == []
    assert result_0.errors == []
    assert result_0.testsRun == 0
    assert result_0.skipped == []
    assert result_0.expectedFailures == []
    assert result_0.unexpectedSuccesses == []
    assert result_0.shouldStop is False
    assert result_0.buffer is False
    assert result_0.tb_locals is False
    assert result_0.stream is None
    assert result_0.showAll is False
    assert result_0.dots is False
    assert result_0.descriptions is None
    assert result_0.data == {'tests': [], 'leaderboard': []}
    assert f'{type(module_0.Result.json).__module__}.{type(module_0.Result.json).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.markdown).__module__}.{type(module_0.Result.markdown).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.score).__module__}.{type(module_0.Result.score).__qualname__}' == 'builtins.property'
    assert f'{type(module_0.Result.maxScore).__module__}.{type(module_0.Result.maxScore).__qualname__}' == 'builtins.property'
    var_0 = module_2.getdoc(result_0)
    result_0.parseExceptions(var_0)